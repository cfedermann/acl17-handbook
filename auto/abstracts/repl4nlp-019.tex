A significant number of neural architectures for reading comprehension have recently been developed and evaluated on large cloze-style datasets. We present experiments supporting the emergence of ``predication structure'' in the hidden state vectors of these readers.  More specifically, we provide evidence that the hidden state vectors represent atomic formulas \$\Phi[c]\$ where \$\Phi\$ is a semantic property (predicate) and \$c\$ is a constant symbol entity identifier.
